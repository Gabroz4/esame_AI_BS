{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ormx8AU28aHG",
        "7c_AsGUe4X95",
        "7pRjQz1k595U",
        "SLkUu5vm54Kj",
        "plaugXLHEk7V",
        "KCIbmyjtckPf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PROGETTO INTELLIGENZA ARTIFICIALE\n",
        "> Stefani Tommaso - Broccoli Gabriele"
      ],
      "metadata": {
        "id": "ormx8AU28aHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FASE 0 - Import\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "7c_AsGUe4X95"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iav3_QCuOn0j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBRegressor\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import xlrd\n",
        "import openpyxl\n",
        "import warnings\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FASE 1 - Esplorazione dati\n",
        "----\n",
        "---"
      ],
      "metadata": {
        "id": "7pRjQz1k595U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carica il dataset\n",
        "filepath = '/content/sample_data/Emissioni 10.000 ab.xls'\n",
        "df = pd.read_excel(filepath)\n",
        "\n",
        "#creo una copia del dataset per non lavorare direttamente e modificare il dataset\n",
        "df1 = df.copy()\n",
        "\n",
        "#stampo gli header del dataset\n",
        "df1.head(5)"
      ],
      "metadata": {
        "id": "NIGPETMlOtUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#estrae header e dati impostando i valori reali\n",
        "header = df1.iloc[1]  #prende la seconda riga del dataset e la imposto come header\n",
        "data_df = df1[3:64]    #seleziono le righe dal 3 al 63 inclusa\n",
        "data_df.columns = header  #imposto l'header del dataset con i valori estratti dalla riga 2\n",
        "\n",
        "data_df.reset_index(drop=True, inplace=True)  #reimposta l'indice del datadet e lo aggiorna\n",
        "data_df.head(5)  #stampo per controllare di aver impostato correttamente i nuovi header"
      ],
      "metadata": {
        "id": "wYzkVGL7SUBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo se ci sono valori nulli\n",
        "data_df.isna().sum()"
      ],
      "metadata": {
        "id": "WN54fBuK3mm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rimuovo valori mancanti dataset\n",
        "data_df.dropna(inplace=True)\n",
        "#ricontrollo che non ci siano altri valori nulli\n",
        "data_df.isna().sum()"
      ],
      "metadata": {
        "id": "DRQLjEQKThVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descrivo il dataset stampando: conteggio, media, deviazione standard,\n",
        "#valore minimo, i quartili e valore massimo per ciascuna colonna numerica.\n",
        "data_df.describe()"
      ],
      "metadata": {
        "id": "gdJMP6DbuwpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo che i tipi delle variabili siano effettivamente i valori effettivi\n",
        "data_df.dtypes"
      ],
      "metadata": {
        "id": "hiq65jGUUtEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#alcuni valori che dovrebbero essere numerici sono trattati come stringhe, quindi li devo convertire\n",
        "\n",
        "#parametri di cui devo cambiare il tipo da object a float\n",
        "parametri = header[4:] # ['Consumo specifico', 'SO2', 'NOx', 'COV', 'CH4', 'CO', 'CO2', 'N2O', 'NH3', 'PM2.5', 'PM10', 'PTS']\n",
        "#converto le colonne da tipo object a tipo numerico\n",
        "data_df[parametri] = data_df[parametri].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "#rimuovo i valori nulli\n",
        "data_df.dropna(inplace=True)\n",
        "\n",
        "#controllo che la sostituzione dei tipi sia avvenuta correttamente\n",
        "data_df.dtypes"
      ],
      "metadata": {
        "id": "mp6bjTKbV25L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo la dimensione del dataset\n",
        "#il primo elemento rappresenta il numero di righe mentre il secondo rappresenta il numero di colonne\n",
        "data_df.shape"
      ],
      "metadata": {
        "id": "4zP2Fet4UfdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stampo le prime righe del dataset per controllare che tutti i passi precedenti siano avvenuti tutti con successo\n",
        "data_df.head(5)"
      ],
      "metadata": {
        "id": "BIwySlLcU75X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descrivo il dataset stampando: conteggio, media, deviazione standard,\n",
        "#valore minimo, i quartili e valore massimo per ciascuna colonna numerica\n",
        "#per controllare che le modifiche precedenti siano avvenute con successo\n",
        "data_df.describe()"
      ],
      "metadata": {
        "id": "JOKw6jX8OtWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo una griglia per rappresentare un grafico per ciascun settore\n",
        "g = sns.FacetGrid(data_df, col=\"Settore\", col_wrap=4, height=4)\n",
        "\n",
        "#mappatura della griglia per mettere un grafico per ogni cella della griglia\n",
        "g.map(plt.scatter, \"Combustibile\", \"Consumo specifico\", alpha=0.7)\n",
        "\n",
        "#imposto dei titoli per ogni cella con il nome del settore corrispondente\n",
        "g.set_titles(col_template=\"{col_name}\")\n",
        "\n",
        "#aggiungo un titolo alla griglia\n",
        "g.fig.suptitle(\"Scatter Plot distribuzione consumo di combustibili per Settore\", y=1.02)\n",
        "\n",
        "#visualizzo la griglia con tutti i grafici al suo interno\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2A1-HJncuQRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo un pairplot per esaminare le correlazioni fra tutti gli elementi del dataset\n",
        "sns.pairplot(data_df, hue=\"Settore\", height=2.5, corner=True, aspect=1)\n",
        "\n",
        "#aggiungo un titolo al grafico totale\n",
        "plt.suptitle(\"Correlazioni fra gli inquinanti per settore\")\n",
        "\n",
        "#visualizzo il pairplot.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mrrJKWtPOtbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calcolo la correlazione tra le colonne del dataset\n",
        "correlation_matrix = data_df.corr()\n",
        "\n",
        "#creo una heatmap per vedere le correlazioni\n",
        "plt.figure(figsize=(20, 9))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "\n",
        "#visualizzo l'heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ukOsWkoZWDul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copio il dataset\n",
        "df2 = data_df.copy()\n",
        "\n",
        "#raggruppo in base alla colonna 'Settore' e sommo i valori del consumo specifico\n",
        "#i primi 5 settori con il consumo specifico più alto vengono selezionati e visualizzati in un grafico a torta.\n",
        "df2.groupby(by=df2[\"Settore\"])[\"Consumo specifico\"].sum().sort_values(ascending=False)[:5].plot(\n",
        "    kind=\"pie\",\n",
        "    autopct=\"%1.2f%%\",\n",
        "    radius=1.5,\n",
        "    wedgeprops={'linewidth': 1.2, 'edgecolor': 'darkorange'}\n",
        ")\n",
        "\n",
        "#specifico le dimensioni del grafico\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "#visualizzo il grafico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mjB1ruBGyAM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#elenco degli inquinanti\n",
        "inquinanti = header[5:] #['SO2', 'NOx', 'COV', 'CH4', 'CO', 'CO2', 'N2O', 'NH3', 'PM2.5', 'PM10', 'PTS']\n",
        "\n",
        "n = len(inquinanti)#calcolo del numero totale di inquinanti\n",
        "ncols = 3#numero di colonne per riga nel grafico\n",
        "#calcolo righe necessarie per organizzare gli inquinanti nel grafico\n",
        "#garantendo che ci sia almeno una colonna per ogni inquinante.\n",
        "nrows = n // ncols if n % ncols == 0 else n // ncols + 1\n",
        "\n",
        "#creo un grafico con numero di celle in base al numero di inquinanti\n",
        "fig, axs = plt.subplots(nrows, ncols, figsize=(ncols*4, nrows*4))\n",
        "\n",
        "#creo un grafico a torta per ciascun inquinante\n",
        "for ax, inquinante in zip(np.ravel(axs), inquinanti):\n",
        "    #calcolo la somma totale dell'inquinante per ogni tipo di combustibile\n",
        "    somme_combustibili = df2.groupby('Combustibile')[inquinante].sum()\n",
        "\n",
        "    #creo il grafico a torta con etichette, percentuali e angolo di inizio specificato\n",
        "    ax.pie(somme_combustibili, labels=somme_combustibili.index, autopct='%1.1f%%', startangle=140)\n",
        "    #assegno al grafico il nome corretto con l'inquinante corrispondente\n",
        "    ax.set_title(f'Emissioni di {inquinante}')\n",
        "\n",
        "#rimuovo assi vuoti per evitare il plotting di grafici vuoti\n",
        "for ax in np.ravel(axs)[len(inquinanti):]:\n",
        "    fig.delaxes(ax)\n",
        "\n",
        "#rimuovo sovrapposizioni\n",
        "plt.tight_layout()\n",
        "\n",
        "#visualizzo il grafico con i grafici a torta\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7a0N0huuyhX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FASE 2 - Machine Learning\n",
        "----\n",
        "---"
      ],
      "metadata": {
        "id": "SLkUu5vm54Kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creo un nuovo dataset con solo le colonne specificate\n",
        "data_prev = data_df[['Settore', 'Combustibile', 'Consumo specifico']]"
      ],
      "metadata": {
        "id": "kc9VR31wzEKL"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#codifico le variabili categoriche 'Settore' e 'Combustibile' utilizzando LabelEncoder per renderle valori numerici\n",
        "label_encoder = LabelEncoder()\n",
        "data_prev['Settore'] = label_encoder.fit_transform(data_prev['Settore'])\n",
        "data_prev['Combustibile'] = label_encoder.fit_transform(data_prev['Combustibile'])\n",
        "\n",
        "#divido il dataset in variabili indipendenti (X) e variabile dipendente (y)\n",
        "#X = input per il modello di machine learning\n",
        "#y = output o variabile target del modello di machine learning.\n",
        "X = data_prev[['Combustibile', 'Consumo specifico']]\n",
        "y = data_prev['Settore']\n",
        "\n",
        "#suddivido il dataset in fase di addestramento(80% del dataset) e fase di test(20% del dataset)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "a6eIY2Xn7EJy"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo e addestro il modello KNeighborsClassifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=3) #2-4 sweet spot\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "#effettuo le previsioni\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "\n",
        "#valuto le prestazioni(accuracy_score)\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "print(f'Accuracy KNeighborsClassifier: {accuracy_knn}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ll2OCby7YGz",
        "outputId": "77688f72-422b-4dfa-f023-d423df9d9fef"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy KNeighborsClassifier: 0.9166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo e addestro il modello SVM (Support Vector Machine)\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "#effettuo le previsioni\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "#valuto le prestazioni(accuracy_score)\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f'Accuracy SVM: {accuracy_svm}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpbbvsJt7ntf",
        "outputId": "4a95f72e-9283-40af-f215-603e6c77a725"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy SVM: 0.9166666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valutazione KNeighborsClassifier\n",
        "print(\"KNeighborsClassifier:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Valutazione SVM\n",
        "print(\"SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "qOOyfaUY8UFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creazione di un dizionario di mapping\n",
        "mappa_settori = {\n",
        "    0: \"Automobili\",\n",
        "    1: \"Veicoli leggeri < 3.5 t\",\n",
        "    2: \"Veicoli pesanti > 3.5 t e autobus\",\n",
        "    3: \"Ciclomotori (< 50 cm3)\",\n",
        "    4: \"Motocicli (> 50 cm3)\",\n",
        "}"
      ],
      "metadata": {
        "id": "wTskZKZznGZs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot dei dati effettivi (dati reali)\n",
        "plt.plot([mappa_settori[val] for val in y_test.values], label='Dati effettivi', color='blue', marker='o')\n",
        "\n",
        "#plot delle previsioni KNeighborsClassifier\n",
        "plt.plot([mappa_settori[val] for val in y_pred_knn], label='Previsioni KNN', color='red', marker='x')\n",
        "\n",
        "#plot delle previsioni SVM\n",
        "plt.plot([mappa_settori[val] for val in y_pred_svm], label='Previsioni SVM', color='green', marker='^')\n",
        "\n",
        "#aggiunta dei nomi agli assi\n",
        "plt.xlabel('Corrispondenze fra previsioni e dati effettivi')\n",
        "plt.ylabel('Settore')\n",
        "\n",
        "#aggiunta di una legenda\n",
        "plt.legend()\n",
        "\n",
        "#visualizzazione del grafico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4PU5aazEo85l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FASE 3 - Rete Neurale\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "plaugXLHEk7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#copio il dataset --> devo pulire la colonna \"tipo legislativo\"\n",
        "df3 = data_df.copy()\n",
        "\n",
        "#funzione per tagliare le stringhe quando incontro \"-\" e prendere solo la parte che lo precede\n",
        "def taglia_alla_barra(stringa):\n",
        "    if ' - ' in stringa:\n",
        "        return stringa.split(' - ')[0]\n",
        "    else:\n",
        "        return stringa\n",
        "\n",
        "#funzione per sostituire i valori anomali con valori conformi al resto del dataset\n",
        "def sostituisci(stringa):\n",
        "    if stringa == 'Conventional':\n",
        "        return 'Euro 0'\n",
        "    elif stringa == 'EEV':\n",
        "        return 'Euro 5'\n",
        "    elif stringa == 'Euro I':\n",
        "        return 'Euro 1'\n",
        "    elif stringa == 'Euro II':\n",
        "        return 'Euro 2'\n",
        "    elif stringa == 'Euro III':\n",
        "        return 'Euro 3'\n",
        "    elif stringa == 'Euro IV':\n",
        "        return 'Euro 4'\n",
        "    elif stringa == 'Euro V':\n",
        "        return 'Euro 5'\n",
        "    elif stringa == 'Euro VI':\n",
        "        return 'Euro 6'\n",
        "    return stringa\n",
        "\n",
        "#applico le funzioni alla colonna \"tipo legislativo\"\n",
        "df3['Tipo legislativo'] = df3['Tipo legislativo'].apply(taglia_alla_barra).apply(sostituisci)"
      ],
      "metadata": {
        "id": "TOEczBk5E1zf"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cancello la colonna \"periodo\" perchè ha la stessa valenza della colonna \"tipo legislativo\" in questa analisi\n",
        "df3 = df3.drop('Periodo', axis=1)"
      ],
      "metadata": {
        "id": "F_AXcwqaQV2W"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#controllo che effettivamente sia stata rimossa la colonna \"periodo\"\n",
        "df3.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57r2mXl4UaCj",
        "outputId": "2da49a42-5d23-4a88-9dc8-91467c52e786"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Settore', 'Combustibile', 'Tipo legislativo', 'Consumo specifico',\n",
              "       'SO2', 'NOx', 'COV', 'CH4', 'CO', 'CO2', 'N2O', 'NH3', 'PM2.5', 'PM10',\n",
              "       'PTS'],\n",
              "      dtype='object', name=1)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo una copia del dataset\n",
        "data_prev2 = df3.copy()"
      ],
      "metadata": {
        "id": "SoztoYi5OkPi"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparazione dati per previsione\n",
        "#codifico le variabili \"Settore\", \"Combustibile\" e \"Tipo legislativo\" utilizzando LabelEncoder come in precedenza\n",
        "data_prev2['Settore'] = label_encoder.fit_transform(data_prev2['Settore'])\n",
        "data_prev2['Combustibile'] = label_encoder.fit_transform(data_prev2['Combustibile'])\n",
        "data_prev2['Tipo legislativo'] = label_encoder.fit_transform(data_prev2['Tipo legislativo'])\n",
        "\n",
        "#divido il dataset in variabili indipendente (X) e variabile dipendente (y) per la previsione del PM10\n",
        "y = data_prev2['PM10']\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_prev2, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lBe7UyKXQJ4z"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inizializzo uno StandardScaler per standardizzare le features numeriche\n",
        "sc = StandardScaler()\n",
        "#standardizzo le features nei set di addestramento e di test (avg = 0, std dev = 1)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#verifica se sono presenti dei valori nulli contadoli\n",
        "data_prev2.isnull().sum()"
      ],
      "metadata": {
        "id": "zR34yPEdSBcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c6a696-12b2-400a-a598-e6d9a6dbbb39"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1\n",
              "Settore              0\n",
              "Combustibile         0\n",
              "Tipo legislativo     0\n",
              "Consumo specifico    0\n",
              "SO2                  0\n",
              "NOx                  0\n",
              "COV                  0\n",
              "CH4                  0\n",
              "CO                   0\n",
              "CO2                  0\n",
              "N2O                  0\n",
              "NH3                  0\n",
              "PM2.5                0\n",
              "PM10                 0\n",
              "PTS                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#guardo quante righe(primo valore dei 2) e quante colonne ha il mio dataset\n",
        "data_prev2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kWQU5PuU76D",
        "outputId": "1c3fe244-0509-4b20-aaf0-593228fe2bdf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo un modello sequenziale --> più specificatamente una regressione lineare(activation = linear)\n",
        "#utilizzando una rete neurale basata su nodi densi --> nodo denso = nodo in cui ogni neurone è connesso al neurone successivo\n",
        "modello = Sequential()\n",
        "#aggiungo alla mia rete neurale uno strato denso con 64 neuroni, input_dim rappresenta il numero di colonne in input\n",
        "modello.add(Dense(128, input_dim=15, activation='relu'))\n",
        "modello.add(Dense(64, activation='relu'))\n",
        "modello.add(Dense(32, activation='relu'))\n",
        "modello.add(Dense(16, activation='relu'))\n",
        "#aggiungo alla mia rete neurale un ultimo strato denso con 1 neurone per avere output lineare\n",
        "modello.add(Dense(1, activation='linear'))  #l'output è la mia previsione del PM10"
      ],
      "metadata": {
        "id": "z3fPvpKl_E5B"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dimensioni del set di addestramento\n",
        "X_train.shape\n",
        "#dimensioni del set di test\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wAuReDnVoFh",
        "outputId": "c55e8bae-5f9b-4835-ea94-b4d5313b81ec"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#specifico l'ottimizzatore e la funzione di perdita\n",
        "modello.compile(optimizer='adam', loss='mean_squared_error')\n",
        "# Addestra il modello sui dati di addestramento per un numero x di epoche\n",
        "modello.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose= 1)"
      ],
      "metadata": {
        "id": "GArFnnCpAnAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uso il modello appena addestrato per fare previsioni del pm10 sui dati di test\n",
        "y_prev=modello.predict(X_test)\n",
        "#stampo le previsioni\n",
        "y_prev"
      ],
      "metadata": {
        "id": "MQ5CUxbEUzZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calcolo l'errore quadratico medio (mean squared error) sui dati di test\n",
        "loss = modello.evaluate(X_test, y_test)\n",
        "#stampo l'errore quadratico medio\n",
        "print(f'Errore quadratico medio: {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpS1qWwVAt0W",
        "outputId": "97f16eea-9d0a-4daa-8a61-545498ffc8d2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step - loss: 453.1045\n",
            "Errore quadratico medio: 453.1044921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#utilizzo gli indici degli elementi come elementi di riferimento per l'asse x\n",
        "x_values = range(len(y_test))\n",
        "\n",
        "#plot dei dati originali\n",
        "plt.plot(x_values, y_test, label='Dati originali')\n",
        "\n",
        "#plot delle previsioni\n",
        "plt.plot(x_values, y_prev, label='Previsioni')\n",
        "\n",
        "#aggiungo una legenda\n",
        "plt.legend()\n",
        "\n",
        "#aggiungo un etichetta all'asse delle y\n",
        "plt.ylabel('PM10')"
      ],
      "metadata": {
        "id": "lzkwcNeUxy4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "FASE 4 - Valutazione modelli / Meta Learning\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "KCIbmyjtckPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#elenco dei modelli di regressione che verrano poi confrontati l'un l'altro per trovare il migliore per questo tipo di dataset\n",
        "models = [\n",
        "    MLPRegressor(),\n",
        "    XGBRegressor(),\n",
        "    LinearRegression(),\n",
        "    RandomForestRegressor(),\n",
        "    KNeighborsRegressor()\n",
        "]"
      ],
      "metadata": {
        "id": "ZRWgVHtqc5Eo"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#variabili per trovare il miglior modello di regressione\n",
        "best_model = None\n",
        "best_score = None\n",
        "best_loss = None\n",
        "\n",
        "#creazione di un unico grafico fuori dal ciclo che racchiuderà tutti gli andamenti dei modelli sopra elencati\n",
        "plt.figure(figsize=(15, 5))\n",
        "#plot dei dati originali\n",
        "plt.plot(x_values, y_test, label='Dati originali')\n",
        "\n",
        "#ciclo per addestrare e valutare tutti i modelli di regressione\n",
        "base_predictions = []\n",
        "for clf in models:\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    base_predictions.append(y_pred.flatten()) #tengo da parte la lista delle previsioni per il meta learning\n",
        "\n",
        "    #calcolo delle metriche di valutazione (R2_score e RMSE)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    print(f\"{clf.__class__.__name__:30}: R2_score: {r2:17}, RMSE: {round(rmse, 6):10}\")\n",
        "\n",
        "    #plot delle previsioni sullo stesso grafico\n",
        "    plt.plot(x_values, y_pred, label=f'{clf.__class__.__name__}')\n",
        "\n",
        "    #aggiorno il miglior modello se necessario\n",
        "    if best_loss is not None:\n",
        "        if best_loss > rmse:\n",
        "            best_model = clf\n",
        "            best_score = r2\n",
        "            best_loss = rmse\n",
        "    else:\n",
        "        best_model = clf\n",
        "        best_score = r2\n",
        "        best_loss = rmse\n",
        "\n",
        "#assegno un etichetta all'asse delle x\n",
        "plt.xlabel('Indice Osservazioni')\n",
        "#assegno un etichetta all'asse delle y\n",
        "plt.ylabel('PM10')\n",
        "#aggiungo una legenda\n",
        "plt.legend()\n",
        "#mostro il grafico\n",
        "plt.show()\n",
        "\n",
        "#stampo il modello di regressione che ha avuto il risultato migliore (R2_score più alto e RMSE più basso)\n",
        "print(\"-\" * 92)\n",
        "print(f\"{best_model.__class__.__name__:30}: R2_score: {best_score}, RMSE: {round(best_loss, 6):10}\")"
      ],
      "metadata": {
        "id": "HgN0sm4uiuok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creazione nuovo set di caratteristiche per il meta-learner\n",
        "meta_features = np.array(base_predictions).T\n",
        "\n",
        "#definizione del meta-learner (modello neurale per regressione)\n",
        "meta_learner = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(models),)),\n",
        "    tf.keras.layers.Dense(1, activation='linear')  # Funzione di attivazione lineare per la regressione\n",
        "])\n",
        "meta_learner.compile(optimizer='adam', loss='mean_squared_error')  # Perdita di errore quadratico medio per la regressione\n",
        "\n",
        "#addestramento del meta-learner\n",
        "meta_learner.fit(meta_features, y_test, epochs=100, batch_size=32)\n",
        "\n",
        "#utilizzo del meta-learner per fare previsioni\n",
        "meta_predictions = meta_learner.predict(meta_features)\n",
        "\n",
        "#plot dei dati originali\n",
        "plt.plot(range(len(y_test)), y_test, label='Dati originali')\n",
        "\n",
        "#plot delle previsioni del meta-modello\n",
        "plt.plot(range(len(meta_predictions)), meta_predictions, label='Previsioni meta-modello')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Indice Osservazioni')\n",
        "plt.ylabel('PM10')\n",
        "plt.title('Previsioni del meta-modello per PM10')\n",
        "\n",
        "#mostra il grafico\n",
        "plt.show()\n",
        "\n",
        "#valutazione prestazioni del meta-learner\n",
        "loss_meta = meta_learner.evaluate(meta_features, y_test)\n",
        "print(f\"Errore quadratico medio del meta-learner: {loss_meta}\")"
      ],
      "metadata": {
        "id": "1RppwbGk1GeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}