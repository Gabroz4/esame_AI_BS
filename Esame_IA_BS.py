# -*- coding: utf-8 -*-
"""Test_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ry20kCd3i3kUo-IJIB529x2_zxIeI6Ik
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense
import xlrd
import openpyxl
import warnings

warnings.filterwarnings("ignore")

"""---
FASE 1
----
---
"""

# Carica il dataset
filepath = '/content/sample_data/Emissioni 10.000 ab.xls'
df = pd.read_excel(filepath)

df1 = df.copy()

df1.head()

#estrae header e dati
header = df1.iloc[1]
data_df = df1[3:63]
data_df.columns = header

data_df.reset_index(drop=True, inplace = True)
data_df.head()

data_df.describe()

data_df.dropna(inplace=True)
data_df.isna().sum()

data_df.dtypes

parametri = ['Consumo specifico', 'SO2', 'NOx', 'COV', 'CH4', 'CO', 'CO2', 'N2O', 'NH3', 'PM2.5', 'PM10', 'PTS']

# Converti le colonne numeriche da tipo "object" a tipo numerico
data_df[parametri] = data_df[parametri].apply(pd.to_numeric, errors='coerce')

# Rimuovi le righe con valori mancanti (NaN)
data_df.dropna(inplace=True)

# Verifica il tipo di dati dopo la conversione
data_df.dtypes

data_df.shape

data_df.head()

data_df.describe()

# Impostare la griglia di facce
g = sns.FacetGrid(data_df, col="Settore", col_wrap=4, height=4)

# Mappare uno scatter plot su ogni faccia
g.map(plt.scatter, "Combustibile", "Consumo specifico", alpha=0.7)

# Aggiungere il titolo alla griglia
g.set_titles(col_template="{col_name}")
g.fig.suptitle("Scatter Plot distribuzione consumo di combustibili per Settore", y=1.02)

# Mostrare i grafici
plt.show()

sns.pairplot(data_df, hue="Settore", height=2.5, corner=True, aspect=1)
plt.suptitle("Correlazioni fra gli inquinanti per settore")
plt.show()

correlation_matrix = data_df.corr()
plt.figure(figsize=(20, 9))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')

plt.show()

df2 = data_df.copy()

df2.groupby(by = df2["Settore"])["Consumo specifico"].sum().sort_values(
ascending=False)[:5].plot(kind="pie",
                                  autopct="%1.2f%%",radius = 1.5,
                                  wedgeprops={'linewidth':1.2,
                                             'edgecolor':'darkorange'})
plt.figure(figsize=(4, 4))
plt.show()

# Elenca tutti gli inquinanti
inquinanti = ['SO2', 'NOx', 'COV', 'CH4', 'CO', 'CO2', 'N2O', 'NH3', 'PM2.5', 'PM10', 'PTS']

# Calcola il numero di righe e colonne per i subplot
n = len(inquinanti)
ncols = 3
nrows = n // ncols if n % ncols == 0 else n // ncols + 1

fig, axs = plt.subplots(nrows, ncols, figsize=(ncols*4, nrows*4))

# Crea il grafico a torta per ogni inquinante
for ax, inquinante in zip(np.ravel(axs), inquinanti):
    # Calcola la somma totale dell'inquinante per ogni tipo di combustibile
    somme_combustibili = df2.groupby('Combustibile')[inquinante].sum()

    ax.pie(somme_combustibili, labels=somme_combustibili.index, autopct='%1.1f%%', startangle=140)
    ax.set_title(f'Emissioni di {inquinante}')

# Rimuovi gli assi vuoti
for ax in np.ravel(axs)[len(inquinanti):]:
    fig.delaxes(ax)

plt.tight_layout()
plt.show()

"""---
FASE 2
----
---
"""

data_prev = data_df[['Settore', 'Combustibile', 'Consumo specifico']]
data_prev.to_csv

# Codifica le variabili categoriche
label_encoder = LabelEncoder()
data_prev['Settore'] = label_encoder.fit_transform(data_prev['Settore'])
data_prev['Combustibile'] = label_encoder.fit_transform(data_prev['Combustibile'])

# Dividi il dataset
X = data_prev[['Combustibile', 'Consumo specifico']]
y = data_prev['Settore']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crea e addestra il modello KNeighborsClassifier
knn_classifier = KNeighborsClassifier(n_neighbors=3)
knn_classifier.fit(X_train, y_train)

# Effettua le previsioni
y_pred_knn = knn_classifier.predict(X_test)

# Valuta le prestazioni
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print(f'Accuracy KNeighborsClassifier: {accuracy_knn}')

# Crea e addestra il modello SVM
svm_classifier = SVC(kernel='linear', C=1.0)
svm_classifier.fit(X_train, y_train)

# Effettua le previsioni
y_pred_svm = svm_classifier.predict(X_test)

# Valuta le prestazioni
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'Accuracy SVM: {accuracy_svm}')

from sklearn.metrics import classification_report

# Valutazione KNeighborsClassifier
print("KNeighborsClassifier:")
print(classification_report(y_test, y_pred_knn))

# Valutazione SVM
print("SVM:")
print(classification_report(y_test, y_pred_svm))

# Plot dei dati effettivi
plt.plot(y_test.values, label='Dati effettivi', color='blue', marker='o')

# Plot delle previsioni KNeighborsClassifier
plt.plot(y_pred_knn, label='Previsioni KNN', color='red', marker='x')

# Plot delle previsioni SVM
plt.plot(y_pred_svm, label='Previsioni SVM', color='green', marker='^')

# Aggiungi etichette agli assi
plt.xlabel('Corrispondenze fra previsioni e dati effettivi')
plt.ylabel('Settore')

# Aggiungi una legenda
plt.legend()

# Mostra il grafico
plt.show()

"""---
FASE 3
---
---
"""

#pulire e dividere di nuovo il dataset prendendo le colonne che servono per la nuova previsione
df3 = data_df.copy()

def taglia_alla_barra(str):
  if ' - ' in str:
    return str.split(' - ')[0]
  else:
    return str

def sostituisci(str):
    if str == 'Conventional':
      return 'Euro 0'
    elif str == 'EEV':
      return 'Euro 5'
    elif str == 'Euro I':
      return 'Euro 1'
    elif str == 'Euro II':
      return 'Euro 2'
    elif str == 'Euro III':
      return 'Euro 3'
    elif str == 'Euro IV':
      return 'Euro 4'
    elif str == 'Euro V':
      return 'Euro 5'
    elif str == 'Euro VI':
      return 'Euro 6'
    return str



# Applica la funzione solo alla colonna 'tipo legislativo'
df3['Tipo legislativo'] = df3['Tipo legislativo'].apply(taglia_alla_barra).apply(sostituisci)

df3 = df3.drop('Periodo', axis=1)

df3.columns

data_prev2 = df3.copy()

data_prev2['Settore'] = label_encoder.fit_transform(data_prev2['Settore'])
data_prev2['Combustibile'] = label_encoder.fit_transform(data_prev2['Combustibile'])
data_prev2['Tipo legislativo'] = label_encoder.fit_transform(data_prev2['Tipo legislativo'])

# Dividi il dataset
y = data_prev2['PM10']
X_train,X_test,y_train,y_test = train_test_split(data_prev2,y,test_size=0.2,random_state=42)

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

df3.isnull().sum()

df3.shape

#applichiamo un modello di regressione lineare
modello = Sequential()
modello.add(Dense(64, input_dim=15, activation='relu'))
modello.add(Dense(32, activation='relu'))
modello.add(Dense(16, activation='relu'))
modello.add(Dense(1, activation='linear'))  # L'output Ã¨ un valore continuo (previsione del PM10)

X_train.shape
X_test.shape

modello.compile(optimizer='adam', loss='mean_squared_error')
modello.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

y_prev=modello.predict(X_test)
y_prev

loss = modello.evaluate(X_test, y_test)
print(f'Errore quadratico medio: {loss}')

# Utilizza l'indice delle osservazioni come asse x
x_values = range(len(y_test))

# Plot dei dati originali
plt.plot(x_values, y_test, label='Dati originali')

# Plot delle previsioni
plt.plot(x_values, y_prev, label='Previsioni')

plt.legend()

plt.ylabel('PM10')

"""---
FASE 4
---
---
"""

models = [
    MLPRegressor(),
    XGBRegressor(),
    LinearRegression(),
    RandomForestRegressor(),
    KNeighborsRegressor()
]

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

best_model = None
best_score = None
best_loss = None

# Creazione di un unico grafico fuori dal ciclo
plt.figure(figsize=(18, 8))
plt.plot(x_values, y_test, label='Dati originali')  # Plot dei dati originali

for clf in models:
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    print(f"{clf.__class__.__name__:30}: R2_score: {r2:17}, RMSE: {round(rmse, 6):10}")

    # Plot delle previsioni sullo stesso grafico
    plt.plot(x_values, y_pred, label=f'{clf.__class__.__name__}')

    if best_loss is not None:
        if best_loss > rmse:
            best_model = clf
            best_score = r2
            best_loss = rmse
    else:
        best_model = clf
        best_score = r2
        best_loss = rmse

plt.xlabel('Osservazioni')
plt.ylabel('PM10')
plt.legend()
plt.show()

print("-" * 92)
print(f"{best_model.__class__.__name__:30}: R2_score: {best_score}, RMSE: {round(best_loss, 6):10}")